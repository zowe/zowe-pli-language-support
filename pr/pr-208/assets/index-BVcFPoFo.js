const __vite__mapDeps=(i,m=__vite__mapDeps,d=(m.f||(m.f=["./main-knAHPi05.js","./index-BdWjBsmI.js","./index-BFuLPLBF.css","./main-EqOA2aSS.js"])))=>i.map(i=>d[i]);
import{X as S,Y as Z,Z as Q,$ as N,a0 as ee,a1 as G,a2 as te,a3 as ne,a4 as re,a5 as ie,a6 as oe,a7 as se,a8 as R,a9 as ae,aa as P,ab as ce,ac as ge,ad as T,ae as ue,af as V,U as de,ag as he,_ as O,e as l,ah as $,q as W,ai as U,aj as q,ak as H,al as z,am as u,an as le,ao as me,ap as pe,aq as M,ar as J,as as x,at as fe,au as _e,av as ke,aw as Te,E as ye,ax as Se,ay as F,az as be,aA as Le,aB as ve,aC as we,l as Ce,aD as ze,aE as Ee,f as Y,aF as y,aG as Me,aH as xe,aI as Ie,a as Pe,aJ as De,aK as K,aL as je,j as Oe,aM as Ae,S as Ne}from"./index-BdWjBsmI.js";class Re extends S{constructor(e,t,n,r,o,s,i){super();this._grammar=e;this._initialState=t;this._containsEmbeddedLanguages=n;this._createBackgroundTokenizer=r;this._backgroundTokenizerShouldOnlyVerifyTokens=o;this._reportTokenizationTime=s;this._reportSlowTokenization=i;this._seenLanguages=[];this._onDidEncounterLanguage=this._register(new Z);this.onDidEncounterLanguage=this._onDidEncounterLanguage.event}get backgroundTokenizerShouldOnlyVerifyTokens(){return this._backgroundTokenizerShouldOnlyVerifyTokens()}getInitialState(){return this._initialState}tokenize(e,t,n){throw new Error("Not supported!")}createBackgroundTokenizer(e,t){if(this._createBackgroundTokenizer){return this._createBackgroundTokenizer(e,t)}return void 0}tokenizeEncoded(e,t,n){const r=Math.random()*1e4<1;const o=this._reportSlowTokenization||r;const s=o?new Q(true):void 0;const i=this._grammar.tokenizeLine2(e,n,500);if(o){const c=s.elapsed();if(r||c>32){this._reportTokenizationTime(c,e.length,r)}}if(i.stoppedEarly){console.warn(`Time limit reached when tokenizing line: ${e.substring(0,100)}`);return new N(i.tokens,n)}if(this._containsEmbeddedLanguages){const c=this._seenLanguages;const g=i.tokens;for(let h=0,m=g.length>>>1;h<m;h++){const E=g[(h<<1)+1];const k=ee.getLanguageId(E);if(!c[k]){c[k]=true;this._onDidEncounterLanguage.fire(k)}}}let a;if(n.equals(i.ruleStack)){a=n}else{a=i.ruleStack}return new N(i.tokens,a)}}class Fe extends S{get backgroundTokenizerShouldOnlyVerifyTokens(){return this._actual.backgroundTokenizerShouldOnlyVerifyTokens}constructor(e,t,n,r){super();this._encodedLanguageId=e;this._actual=t;this._maxTokenizationLineLength=r;this._register(G(this._maxTokenizationLineLength));this._register(n)}getInitialState(){return this._actual.getInitialState()}tokenize(e,t,n){throw new Error("Not supported!")}tokenizeEncoded(e,t,n){if(e.length>=this._maxTokenizationLineLength.get()){return te(this._encodedLanguageId,n)}return this._actual.tokenizeEncoded(e,t,n)}createBackgroundTokenizer(e,t){if(this._actual.createBackgroundTokenizer){return this._actual.createBackgroundTokenizer(e,t)}else{return void 0}}}class v{static{this.CHANNEL_NAME="textMateWorkerHost"}static getChannel(e){return e.getChannel(v.CHANNEL_NAME)}static setChannel(e,t){e.setChannel(v.CHANNEL_NAME,t)}}class Be{constructor(e){this.edits=e.slice().sort(ne(t=>t.offset,re))}applyToArray(e){for(let t=this.edits.length-1;t>=0;t--){const n=this.edits[t];e.splice(n.offset,n.length,...new Array(n.newLength))}}}class Ge{constructor(e,t,n){this.offset=e;this.length=t;this.newLength=n}toString(){return`[${this.offset}, +${this.length}) -> +${this.newLength}}`}}class w{static fromMany(e){const t=e.map(n=>new w(n));return new Ve(t)}constructor(e){this.transformation=e;this.idx=0;this.offset=0}transform(e){let t=this.transformation.edits[this.idx];while(t&&t.offset+t.length<=e){this.offset+=t.newLength-t.length;this.idx++;t=this.transformation.edits[this.idx]}if(t&&t.offset<=e){return void 0}return e+this.offset}}class Ve{constructor(e){this.transformers=e}transform(e){for(const t of this.transformers){const n=t.transform(e);if(n===void 0){return void 0}e=n}return e}}class A extends S{static{this._id=0}constructor(e,t,n,r,o,s){super();this._model=e;this._worker=t;this._languageIdCodec=n;this._backgroundTokenizationStore=r;this._configurationService=o;this._maxTokenizationLineLength=s;this.controllerId=A._id++;this._pendingChanges=[];this._states=new ie;this._loggingEnabled=oe("editor.experimental.asyncTokenizationLogging",false,this._configurationService);this._register(G(this._loggingEnabled));this._register(this._model.onDidChangeContent(c=>{if(this._shouldLog){console.log("model change",{fileName:this._model.uri.fsPath.split("\\").pop(),changes:I(c.changes)})}this._worker.$acceptModelChanged(this.controllerId,c);this._pendingChanges.push(c)}));this._register(this._model.onDidChangeLanguage(c=>{const g=this._model.getLanguageId();const h=this._languageIdCodec.encodeLanguageId(g);this._worker.$acceptModelLanguageChanged(this.controllerId,g,h)}));const i=this._model.getLanguageId();const a=this._languageIdCodec.encodeLanguageId(i);this._worker.$acceptNewModel({uri:this._model.uri,versionId:this._model.getVersionId(),lines:this._model.getLinesContent(),EOL:this._model.getEOL(),languageId:i,encodedLanguageId:a,maxTokenizationLineLength:this._maxTokenizationLineLength.get(),controllerId:this.controllerId});this._register(se(c=>{const g=this._maxTokenizationLineLength.read(c);this._worker.$acceptMaxTokenizationLineLength(this.controllerId,g)}))}dispose(){super.dispose();this._worker.$acceptRemovedModel(this.controllerId)}requestTokens(e,t){this._worker.$retokenize(this.controllerId,e,t)}async setTokensAndStates(e,t,n,r){if(this.controllerId!==e){return}let o=R.deserialize(new Uint8Array(n));if(this._shouldLog){console.log("received background tokenization result",{fileName:this._model.uri.fsPath.split("\\").pop(),updatedTokenLines:o.map(i=>i.getLineRange()).join(" & "),updatedStateLines:r.map(i=>new ae(i.startLineNumber,i.startLineNumber+i.stateDeltas.length).toString()).join(" & ")})}if(this._shouldLog){const i=this._pendingChanges.filter(a=>a.versionId<=t).map(a=>a.changes).map(a=>I(a)).join(" then ");console.log("Applying changes to local states",i)}while(this._pendingChanges.length>0&&this._pendingChanges[0].versionId<=t){const i=this._pendingChanges.shift();this._states.acceptChanges(i.changes)}if(this._pendingChanges.length>0){if(this._shouldLog){const c=this._pendingChanges.map(g=>g.changes).map(g=>I(g)).join(" then ");console.log("Considering non-processed changes",c)}const i=w.fromMany(this._pendingChanges.map(c=>B(c.changes)));const a=new R;for(const c of o){for(let g=c.startLineNumber;g<=c.endLineNumber;g++){const h=i.transform(g-1);if(h!==void 0){a.add(g,c.getLineTokens(g))}}}o=a.finalize();for(const c of this._pendingChanges){for(const g of c.changes){for(let h=0;h<o.length;h++){o[h].applyEdit(g.range,g.text)}}}}const s=w.fromMany(this._pendingChanges.map(i=>B(i.changes)));if(!this._applyStateStackDiffFn||!this._initialState){const{applyStateStackDiff:i,INITIAL:a}=await P(async()=>{const{applyStateStackDiff:c,INITIAL:g}=await import("./main-knAHPi05.js").then(h=>h.m);return{applyStateStackDiff:c,INITIAL:g}},true?__vite__mapDeps([0,1,2]):void 0,import.meta.url).then(c=>c.default??c);this._applyStateStackDiffFn=i;this._initialState=a}for(const i of r){let a=i.startLineNumber<=1?this._initialState:this._states.getEndState(i.startLineNumber-1);for(let c=0;c<i.stateDeltas.length;c++){const g=i.stateDeltas[c];let h;if(g){h=this._applyStateStackDiffFn(a,g);this._states.setEndState(i.startLineNumber+c,h)}else{h=this._states.getEndState(i.startLineNumber+c)}const m=s.transform(i.startLineNumber+c-1);if(m!==void 0){this._backgroundTokenizationStore.setEndState(m+1,h)}if(i.startLineNumber+c>=this._model.getLineCount()-1){this._backgroundTokenizationStore.backgroundTokenizationFinished()}a=h}}this._backgroundTokenizationStore.setTokens(o)}get _shouldLog(){return this._loggingEnabled.get()}}function B(d){return new Be(d.map(e=>new Ge(e.range.startLineNumber-1,e.range.endLineNumber-e.range.startLineNumber+1,ce(e.text)[0]+1)))}function I(d){return d.map(e=>ge.lift(e.range).toString()+" => "+e.text).join(" & ")}var b;let D=class tt{static{b=this}static{this._reportedMismatchingTokens=false}constructor(e,t,n,r,o,s,i){this._reportTokenizationTime=e;this._shouldTokenizeAsync=t;this._extensionResourceLoaderService=n;this._configurationService=r;this._languageService=o;this._notificationService=s;this._telemetryService=i;this._workerProxyPromise=null;this._worker=null;this._workerProxy=null;this._workerTokenizerControllers=new Map;this._currentTheme=null;this._currentTokenColorMap=null;this._grammarDefinitions=[]}dispose(){this._disposeWorker()}createBackgroundTokenizer(e,t,n){if(!this._shouldTokenizeAsync()||e.isTooLargeForSyncing()){return void 0}const r=new T;const o=this._getWorkerProxy().then(s=>{if(r.isDisposed||!s){return void 0}const i={controller:void 0,worker:this._worker};r.add($e(e,()=>{const a=new A(e,s,this._languageService.languageIdCodec,t,this._configurationService,n);i.controller=a;this._workerTokenizerControllers.set(a.controllerId,a);return he(()=>{i.controller=void 0;this._workerTokenizerControllers.delete(a.controllerId);a.dispose()})}));return i});return{dispose(){r.dispose()},requestTokens:async(s,i)=>{const a=await o;if(a?.controller&&a.worker===this._worker){a.controller.requestTokens(s,i)}},reportMismatchingTokens:s=>{if(b._reportedMismatchingTokens){return}b._reportedMismatchingTokens=true;this._notificationService.error({message:"Async Tokenization Token Mismatch in line "+s,name:"Async Tokenization Token Mismatch"});this._telemetryService.publicLog2("asyncTokenizationMismatchingTokens",{})}}}setGrammarDefinitions(e){this._grammarDefinitions=e;this._disposeWorker()}acceptTheme(e,t){this._currentTheme=e;this._currentTokenColorMap=t;if(this._currentTheme&&this._currentTokenColorMap&&this._workerProxy){this._workerProxy.$acceptTheme(this._currentTheme,this._currentTokenColorMap)}}_getWorkerProxy(){if(!this._workerProxyPromise){this._workerProxyPromise=this._createWorkerProxy()}return this._workerProxyPromise}async _createWorkerProxy(){const e={grammarDefinitions:this._grammarDefinitions,onigurumaWASMUri:new URL(""+new URL("onig-Du5pRr7Y.wasm",import.meta.url).href,import.meta.url).href};const t=this._worker=ue(V.asBrowserUri("vs/workbench/services/textMate/browser/backgroundTokenization/worker/textMateTokenizationWorker.workerMain.js"),"TextMateWorker");v.setChannel(t,{$readFile:async n=>{const r=de.revive(n);return this._extensionResourceLoaderService.readExtensionResource(r)},$setTokensAndStates:async(n,r,o,s)=>{const i=this._workerTokenizerControllers.get(n);if(i){i.setTokensAndStates(n,r,o,s)}},$reportTokenizationTime:(n,r,o,s,i)=>{this._reportTokenizationTime(n,r,o,s,i)}});await t.proxy.$init(e);if(this._worker!==t){return null}this._workerProxy=t.proxy;if(this._currentTheme&&this._currentTokenColorMap){this._workerProxy.$acceptTheme(this._currentTheme,this._currentTokenColorMap)}return t.proxy}_disposeWorker(){for(const e of this._workerTokenizerControllers.values()){e.dispose()}this._workerTokenizerControllers.clear();if(this._worker){this._worker.dispose();this._worker=null}this._workerProxy=null;this._workerProxyPromise=null}};D=b=O([l(2,$),l(3,W),l(4,U),l(5,q),l(6,H)],D);function $e(d,e){const t=new T;const n=t.add(new T);function r(){if(d.isAttachedToEditor()){n.add(e())}else{n.clear()}}r();t.add(d.onDidChangeAttached(()=>{r()}));return t}class We{constructor(){this._scopeNameToLanguageRegistration=Object.create(null)}reset(){this._scopeNameToLanguageRegistration=Object.create(null)}register(e){this._scopeNameToLanguageRegistration[e.scopeName]=e}getGrammarDefinition(e){return this._scopeNameToLanguageRegistration[e]||null}}const L="No TM Grammar registered for this language.";class Ue extends S{constructor(e,t,n,r){super();this._host=e;this._initialState=n.INITIAL;this._scopeRegistry=new We;this._injections={};this._injectedEmbeddedLanguages={};this._languageToScope=new Map;this._grammarRegistry=this._register(new n.Registry({onigLib:r,loadGrammar:async o=>{const s=this._scopeRegistry.getGrammarDefinition(o);if(!s){this._host.logTrace(`No grammar found for scope ${o}`);return null}const i=s.location;try{const a=await this._host.readFile(i);return n.parseRawGrammar(a,i.path)}catch(a){this._host.logError(`Unable to load and parse grammar for scope ${o} from ${i}`,a);return null}},getInjections:o=>{const s=o.split(".");let i=[];for(let a=1;a<=s.length;a++){const c=s.slice(0,a).join(".");i=[...i,...this._injections[c]||[]]}return i}}));for(const o of t){this._scopeRegistry.register(o);if(o.injectTo){for(const s of o.injectTo){let i=this._injections[s];if(!i){this._injections[s]=i=[]}i.push(o.scopeName)}if(o.embeddedLanguages){for(const s of o.injectTo){let i=this._injectedEmbeddedLanguages[s];if(!i){this._injectedEmbeddedLanguages[s]=i=[]}i.push(o.embeddedLanguages)}}}if(o.language){this._languageToScope.set(o.language,o.scopeName)}}}has(e){return this._languageToScope.has(e)}setTheme(e,t){this._grammarRegistry.setTheme(e,t)}getColorMap(){return this._grammarRegistry.getColorMap()}async createGrammar(e,t){const n=this._languageToScope.get(e);if(typeof n!=="string"){throw new Error(L)}const r=this._scopeRegistry.getGrammarDefinition(n);if(!r){throw new Error(L)}const o=r.embeddedLanguages;if(this._injectedEmbeddedLanguages[n]){const a=this._injectedEmbeddedLanguages[n];for(const c of a){for(const g of Object.keys(c)){o[g]=c[g]}}}const s=Object.keys(o).length>0;let i;try{i=await this._grammarRegistry.loadGrammarWithConfiguration(n,t,{embeddedLanguages:o,tokenTypes:r.tokenTypes,balancedBracketSelectors:r.balancedBracketSelectors,unbalancedBracketSelectors:r.unbalancedBracketSelectors})}catch(a){if(a.message&&a.message.startsWith("No grammar provided for")){throw new Error(L)}throw a}return{languageId:e,grammar:i,initialState:this._initialState,containsEmbeddedLanguages:s,sourceExtensionId:r.sourceExtensionId}}}const f=z.registerExtensionPoint({extensionPoint:"grammars",deps:[le],jsonSchema:{description:u(12450,"Contributes textmate tokenizers."),type:"array",defaultSnippets:[{body:[{language:"${1:id}",scopeName:"source.${2:id}",path:"./syntaxes/${3:id}.tmLanguage."}]}],items:{type:"object",defaultSnippets:[{body:{language:"${1:id}",scopeName:"source.${2:id}",path:"./syntaxes/${3:id}.tmLanguage."}}],properties:{language:{description:u(12451,"Language identifier for which this syntax is contributed to."),type:"string"},scopeName:{description:u(12452,"Textmate scope name used by the tmLanguage file."),type:"string"},path:{description:u(12453,"Path of the tmLanguage file. The path is relative to the extension folder and typically starts with './syntaxes/'."),type:"string"},embeddedLanguages:{description:u(12454,"A map of scope name to language id if this grammar contains embedded languages."),type:"object"},tokenTypes:{description:u(12455,"A map of scope name to token types."),type:"object",additionalProperties:{enum:["string","comment","other"]}},injectTo:{description:u(12456,"List of language scope names to which this grammar is injected to."),type:"array",items:{type:"string"}},balancedBracketScopes:{description:u(12457,"Defines which scope names contain balanced brackets."),type:"array",items:{type:"string"},default:["*"]},unbalancedBracketScopes:{description:u(12458,"Defines which scope names do not contain balanced brackets."),type:"array",items:{type:"string"},default:[]}},required:["scopeName","path"]}}});var _;let j=class nt extends S{static{_=this}static{this.reportTokenizationTimeCounter={sync:0,async:0}}constructor(e,t,n,r,o,s,i,a,c,g){super();this._languageService=e;this._themeService=t;this._extensionResourceLoaderService=n;this._notificationService=r;this._logService=o;this._configurationService=s;this._progressService=i;this._environmentService=a;this._instantiationService=c;this._telemetryService=g;this._createdModes=[];this._encounteredLanguages=[];this._debugMode=false;this._debugModePrintFunc=()=>{};this._grammarDefinitions=null;this._grammarFactory=null;this._tokenizersRegistrations=this._register(new T);this._currentTheme=null;this._currentTokenColorMap=null;this._threadedBackgroundTokenizerFactory=this._instantiationService.createInstance(D,(h,m,E,k,X)=>this._reportTokenizationTime(h,m,E,k,true,X),()=>this.getAsyncTokenizationEnabled());this._vscodeOniguruma=null;this._styleElement=me();this._styleElement.className="vscode-tokens-styles";f.setHandler(h=>this._handleGrammarsExtPoint(h));this._updateTheme(this._themeService.getColorTheme(),true);this._register(this._themeService.onDidColorThemeChange(()=>{this._updateTheme(this._themeService.getColorTheme(),false)}));this._register(this._languageService.onDidRequestRichLanguageFeatures(h=>{this._createdModes.push(h)}))}getAsyncTokenizationEnabled(){return!!this._configurationService.getValue("editor.experimental.asyncTokenization")}getAsyncTokenizationVerification(){return!!this._configurationService.getValue("editor.experimental.asyncTokenizationVerification")}_handleGrammarsExtPoint(e){this._grammarDefinitions=null;if(this._grammarFactory){this._grammarFactory.dispose();this._grammarFactory=null}this._tokenizersRegistrations.clear();this._grammarDefinitions=[];for(const t of e){const n=t.value;for(const r of n){const o=this._validateGrammarDefinition(t,r);if(o){this._grammarDefinitions.push(o);if(o.language){const s=new pe(()=>this._createTokenizationSupport(o.language));this._tokenizersRegistrations.add(s);this._tokenizersRegistrations.add(M.registerFactory(o.language,s))}}}}this._threadedBackgroundTokenizerFactory.setGrammarDefinitions(this._grammarDefinitions);for(const t of this._createdModes){M.getOrCreate(t)}}_validateGrammarDefinition(e,t){if(!Je(e.description.extensionLocation,t,e.collector,this._languageService)){return null}const n=J(e.description.extensionLocation,t.path);const r=Object.create(null);if(t.embeddedLanguages){const a=Object.keys(t.embeddedLanguages);for(let c=0,g=a.length;c<g;c++){const h=a[c];const m=t.embeddedLanguages[h];if(typeof m!=="string"){continue}if(this._languageService.isRegisteredLanguageId(m)){r[h]=this._languageService.languageIdCodec.encodeLanguageId(m)}}}const o=Object.create(null);if(t.tokenTypes){const a=Object.keys(t.tokenTypes);for(const c of a){const g=t.tokenTypes[c];switch(g){case"string":o[c]=x.String;break;case"other":o[c]=x.Other;break;case"comment":o[c]=x.Comment;break}}}const s=t.language&&this._languageService.isRegisteredLanguageId(t.language)?t.language:void 0;function i(a,c){if(!Array.isArray(a)){return c}if(!a.every(g=>typeof g==="string")){return c}return a}return{location:n,language:s,scopeName:t.scopeName,embeddedLanguages:r,tokenTypes:o,injectTo:t.injectTo,balancedBracketSelectors:i(t.balancedBracketScopes,["*"]),unbalancedBracketSelectors:i(t.unbalancedBracketScopes,[]),sourceExtensionId:e.description.id}}startDebugMode(e,t){if(this._debugMode){this._notificationService.error(u(12439,"Already Logging."));return}this._debugModePrintFunc=e;this._debugMode=true;if(this._debugMode){this._progressService.withProgress({location:fe.Notification,buttons:[u(12440,"Stop")]},n=>{n.report({message:u(12441,"Preparing to log TM Grammar parsing. Press Stop when finished.")});return this._getVSCodeOniguruma().then(r=>{r.setDefaultDebugCall(true);n.report({message:u(12442,"Now logging TM Grammar parsing. Press Stop when finished.")});return new Promise((o,s)=>{})})},n=>{this._getVSCodeOniguruma().then(r=>{this._debugModePrintFunc=()=>{};this._debugMode=false;r.setDefaultDebugCall(false);t()})})}}_canCreateGrammarFactory(){return!!this._grammarDefinitions}async _getOrCreateGrammarFactory(){if(this._grammarFactory){return this._grammarFactory}const[e,t]=await Promise.all([P(()=>import("./main-knAHPi05.js").then(r=>r.m),true?__vite__mapDeps([0,1,2]):void 0,import.meta.url).then(r=>r.default??r),this._getVSCodeOniguruma()]);const n=Promise.resolve({createOnigScanner:r=>t.createOnigScanner(r),createOnigString:r=>t.createOnigString(r)});if(this._grammarFactory){return this._grammarFactory}this._grammarFactory=new Ue({logTrace:r=>this._logService.trace(r),logError:(r,o)=>this._logService.error(r,o),readFile:r=>this._extensionResourceLoaderService.readExtensionResource(r)},this._grammarDefinitions||[],e,n);this._updateTheme(this._themeService.getColorTheme(),true);return this._grammarFactory}async _createTokenizationSupport(e){if(!this._languageService.isRegisteredLanguageId(e)){return null}if(!this._canCreateGrammarFactory()){return null}try{const t=await this._getOrCreateGrammarFactory();if(!t.has(e)){return null}const n=this._languageService.languageIdCodec.encodeLanguageId(e);const r=await t.createGrammar(e,n);if(!r.grammar){return null}const o=Ye("editor.maxTokenizationLineLength",e,-1,this._configurationService);const s=new T;const i=s.add(new Re(r.grammar,r.initialState,r.containsEmbeddedLanguages,(a,c)=>this._threadedBackgroundTokenizerFactory.createBackgroundTokenizer(a,c,o),()=>this.getAsyncTokenizationVerification(),(a,c,g)=>{this._reportTokenizationTime(a,e,r.sourceExtensionId,c,false,g)},true));s.add(i.onDidEncounterLanguage(a=>{if(!this._encounteredLanguages[a]){const c=this._languageService.languageIdCodec.decodeLanguageId(a);this._encounteredLanguages[a]=true;this._languageService.requestBasicLanguageFeatures(c)}}));return new Fe(n,i,s,o)}catch(t){if(t.message&&t.message===L){return null}_e(t);return null}}_updateTheme(e,t){if(!t&&this._currentTheme&&this._currentTokenColorMap&&He(this._currentTheme.settings,e.tokenColors)&&ke(this._currentTokenColorMap,e.tokenColorMap)){return}this._currentTheme={name:e.label,settings:e.tokenColors};this._currentTokenColorMap=e.tokenColorMap;this._grammarFactory?.setTheme(this._currentTheme,this._currentTokenColorMap);const n=qe(this._currentTokenColorMap);const r=Te(n);this._styleElement.textContent=r;M.setColorMap(n);if(this._currentTheme&&this._currentTokenColorMap){this._threadedBackgroundTokenizerFactory.acceptTheme(this._currentTheme,this._currentTokenColorMap)}}async createTokenizer(e){if(!this._languageService.isRegisteredLanguageId(e)){return null}const t=await this._getOrCreateGrammarFactory();if(!t.has(e)){return null}const n=this._languageService.languageIdCodec.encodeLanguageId(e);const{grammar:r}=await t.createGrammar(e,n);return r}_getVSCodeOniguruma(){if(!this._vscodeOniguruma){this._vscodeOniguruma=(async()=>{const[e,t]=await Promise.all([P(()=>import("./main-EqOA2aSS.js").then(n=>n.m),true?__vite__mapDeps([3,1,2]):void 0,import.meta.url).then(n=>n.default??n),this._loadVSCodeOnigurumaWASM()]);await e.loadWASM({data:t,print:n=>{this._debugModePrintFunc(n)}});return e})()}return this._vscodeOniguruma}async _loadVSCodeOnigurumaWASM(){if(ye){const e=await fetch(new URL(""+new URL("onig-Du5pRr7Y.wasm",import.meta.url).href,import.meta.url).href);return await e.arrayBuffer()}else{const e=await fetch(V.asBrowserUri(`${Se}/vscode-oniguruma/release/onig.wasm`).toString(true));return e}}_reportTokenizationTime(e,t,n,r,o,s){const i=o?"async":"sync";if(_.reportTokenizationTimeCounter[i]>50){return}if(_.reportTokenizationTimeCounter[i]===0){setTimeout(()=>{_.reportTokenizationTimeCounter[i]=0},1e3*60*60)}_.reportTokenizationTimeCounter[i]++;this._telemetryService.publicLog2("editor.tokenizedLine",{timeMs:e,languageId:t,lineLength:r,fromWorker:o,sourceExtensionId:n,isRandomSample:s,tokenizationSetting:this.getAsyncTokenizationEnabled()?this.getAsyncTokenizationVerification()?2:1:0})}};j=_=O([l(0,U),l(1,we),l(2,$),l(3,q),l(4,Ce),l(5,W),l(6,ze),l(7,Ee),l(8,Y),l(9,H)],j);function qe(d){const e=[null];for(let t=1,n=d.length;t<n;t++){e[t]=ve.fromHex(d[t])}return e}function He(d,e){if(!e||!d||e.length!==d.length){return false}for(let t=e.length-1;t>=0;t--){const n=e[t];const r=d[t];if(n.scope!==r.scope){return false}const o=n.settings;const s=r.settings;if(o&&s){if(o.fontStyle!==s.fontStyle||o.foreground!==s.foreground||o.background!==s.background){return false}}else if(!o||!s){return false}}return true}function Je(d,e,t,n){if(e.language&&(typeof e.language!=="string"||!n.isRegisteredLanguageId(e.language))){t.error(u(12443,"Unknown language in `contributes.{0}.language`. Provided value: {1}",f.name,String(e.language)));return false}if(!e.scopeName||typeof e.scopeName!=="string"){t.error(u(12444,"Expected string in `contributes.{0}.scopeName`. Provided value: {1}",f.name,String(e.scopeName)));return false}if(!e.path||typeof e.path!=="string"){t.error(u(12445,"Expected string in `contributes.{0}.path`. Provided value: {1}",f.name,String(e.path)));return false}if(e.injectTo&&(!Array.isArray(e.injectTo)||e.injectTo.some(o=>typeof o!=="string"))){t.error(u(12446,"Invalid value in `contributes.{0}.injectTo`. Must be an array of language scope names. Provided value: {1}",f.name,JSON.stringify(e.injectTo)));return false}if(e.embeddedLanguages&&!F(e.embeddedLanguages)){t.error(u(12447,"Invalid value in `contributes.{0}.embeddedLanguages`. Must be an object map from scope name to language. Provided value: {1}",f.name,JSON.stringify(e.embeddedLanguages)));return false}if(e.tokenTypes&&!F(e.tokenTypes)){t.error(u(12448,"Invalid value in `contributes.{0}.tokenTypes`. Must be an object map from scope name to token type. Provided value: {1}",f.name,JSON.stringify(e.tokenTypes)));return false}const r=J(d,e.path);if(!be(r,d)){t.warn(u(12449,"Expected `contributes.{0}.path` ({1}) to be included inside extension's folder ({2}). This might make the extension non-portable.",f.name,r.path,d.path))}return true}function Ye(d,e,t,n){return Le(r=>n.onDidChangeConfiguration(o=>{if(o.affectsConfiguration(d,{overrideIdentifier:e})){r(o)}}),()=>n.getValue(d,{overrideIdentifier:e})??t)}const p=Ie();const Ke=z.registerExtensionPoint({extensionPoint:"semanticTokenTypes",jsonSchema:{description:u(12646,"Contributes semantic token types."),type:"array",items:{type:"object",properties:{id:{type:"string",description:u(12647,"The identifier of the semantic token type"),pattern:y,patternErrorMessage:u(12648,"Identifiers should be in the form letterOrDigit[_-letterOrDigit]*")},superType:{type:"string",description:u(12649,"The super type of the semantic token type"),pattern:y,patternErrorMessage:u(12650,"Super types should be in the form letterOrDigit[_-letterOrDigit]*")},description:{type:"string",description:u(12651,"The description of the semantic token type")}}}}});const Xe=z.registerExtensionPoint({extensionPoint:"semanticTokenModifiers",jsonSchema:{description:u(12652,"Contributes semantic token modifiers."),type:"array",items:{type:"object",properties:{id:{type:"string",description:u(12653,"The identifier of the semantic token modifier"),pattern:y,patternErrorMessage:u(12654,"Identifiers should be in the form letterOrDigit[_-letterOrDigit]*")},description:{type:"string",description:u(12655,"The description of the semantic token modifier")}}}}});const Ze=z.registerExtensionPoint({extensionPoint:"semanticTokenScopes",jsonSchema:{description:u(12656,"Contributes semantic token scope maps."),type:"array",items:{type:"object",properties:{language:{description:u(12657,"Lists the languge for which the defaults are."),type:"string"},scopes:{description:u(12658,"Maps a semantic token (described by semantic token selector) to one or more textMate scopes used to represent that token."),type:"object",additionalProperties:{type:"array",items:{type:"string"}}}}}}});class Qe{constructor(){function e(t,n,r){if(typeof t.id!=="string"||t.id.length===0){r.error(u(12659,"'configuration.{0}.id' must be defined and can not be empty",n));return false}if(!t.id.match(y)){r.error(u(12660,"'configuration.{0}.id' must follow the pattern letterOrDigit[-_letterOrDigit]*",n));return false}const o=t.superType;if(o&&!o.match(y)){r.error(u(12661,"'configuration.{0}.superType' must follow the pattern letterOrDigit[-_letterOrDigit]*",n));return false}if(typeof t.description!=="string"||t.id.length===0){r.error(u(12662,"'configuration.{0}.description' must be defined and can not be empty",n));return false}return true}Ke.setHandler((t,n)=>{for(const r of n.added){const o=r.value;const s=r.collector;if(!o||!Array.isArray(o)){s.error(u(12663,"'configuration.semanticTokenType' must be an array"));return}for(const i of o){if(e(i,"semanticTokenType",s)){p.registerTokenType(i.id,i.description,i.superType)}}}for(const r of n.removed){const o=r.value;for(const s of o){p.deregisterTokenType(s.id)}}});Xe.setHandler((t,n)=>{for(const r of n.added){const o=r.value;const s=r.collector;if(!o||!Array.isArray(o)){s.error(u(12664,"'configuration.semanticTokenModifier' must be an array"));return}for(const i of o){if(e(i,"semanticTokenModifier",s)){p.registerTokenModifier(i.id,i.description)}}}for(const r of n.removed){const o=r.value;for(const s of o){p.deregisterTokenModifier(s.id)}}});Ze.setHandler((t,n)=>{for(const r of n.added){const o=r.value;const s=r.collector;if(!o||!Array.isArray(o)){s.error(u(12665,"'configuration.semanticTokenScopes' must be an array"));return}for(const i of o){if(i.language&&typeof i.language!=="string"){s.error(u(12666,"'configuration.semanticTokenScopes.language' must be a string"));continue}if(!i.scopes||typeof i.scopes!=="object"){s.error(u(12667,"'configuration.semanticTokenScopes.scopes' must be defined as an object"));continue}for(const a in i.scopes){const c=i.scopes[a];if(!Array.isArray(c)||c.some(g=>typeof g!=="string")){s.error(u(12668,"'configuration.semanticTokenScopes.scopes' values must be an array of strings"));continue}try{const g=p.parseTokenSelector(a,i.language);p.registerTokenStyleDefault(g,{scopesToProbe:c.map(h=>h.split(" "))})}catch(g){s.error(u(12669,"configuration.semanticTokenScopes.scopes': Problems parsing selector {0}.",a))}}}}for(const r of n.removed){const o=r.value;for(const s of o){for(const i in s.scopes){const a=s.scopes[i];try{const c=p.parseTokenSelector(i,s.language);p.registerTokenStyleDefault(c,{scopesToProbe:a.map(g=>g.split(" "))})}catch(c){}}}}})}}let C=class rt{static{this.ID="workbench.contrib.tokenClassificationExtensionPoint"}constructor(e){this.instantiationService=e;this.instantiationService.createInstance(Qe)}};C=O([l(0,Y)],C);Me(C.ID,C,xe.BlockStartup);je(async d=>{void d.get(Oe).when(Ae.Ready).then(()=>{Ne.get(K)})});function it(){return{...De(),[K.toString()]:new Pe(j,[],false)}}export{K as ITextMateTokenizationService,it as default};
